{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98f401cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "from dataclasses import dataclass\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "from scipy.ndimage import maximum_filter, minimum_filter\n",
    "from datetime import datetime\n",
    "from metpy.units import units\n",
    "import metpy.calc as mpcalc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d5311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION AND DATA CLASSES\n",
    "# ============================================================================\n",
    "\n",
    "@dataclass\n",
    "class VariableNames:\n",
    "    \"\"\"Variable names for different model outputs.\"\"\"\n",
    "    msl_pressure: str = \"psl\"  # Mean sea-level pressure\n",
    "    pressure: str = \"plev\"  # Pressure levels\n",
    "    temperature: str = \"ta\"  # Temperature\n",
    "    specific_humidity: str = \"hus\"  # Specific humidity\n",
    "    u_wind: str = \"ua\"  # Zonal wind\n",
    "    v_wind: str = \"va\"  # Meridional wind\n",
    "    w_wind: str = \"wa\"  # Meridional wind\n",
    "    u_wind_10m: str = \"uas\"  # 10m zonal wind\n",
    "    v_wind_10m: str = \"vas\"  # 10m meridional wind\n",
    "    latitude: str = \"lat\"\n",
    "    longitude: str = \"lon\"\n",
    "    time: str = \"time\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CycloneTrackingConfig:\n",
    "    \"\"\"Configuration for cyclone tracking parameters.\"\"\"\n",
    "    search_radius_km: float = 500.0  # Initial search radius\n",
    "    max_speed_kmh: float = 100.0  # Maximum cyclone movement speed\n",
    "    min_pressure_threshold: float = 1015.0  # Pressure threshold for detection\n",
    "    footprint_size: int = 10  # Footprint for local minima detection\n",
    "    intensity_threshold: float = 2.0  # Minimum pressure gradient (hPa)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PlotConfig:\n",
    "    \"\"\"Configuration for plotting.\"\"\"\n",
    "    figsize: Tuple[int, int] = (12, 8)\n",
    "    dpi: int = 300\n",
    "    colors: List[str] = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.colors is None:\n",
    "            self.colors = [\n",
    "                \"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\",\n",
    "                \"#8c564b\", \"#e377c2\", \"#7f7f7f\", \"#bcbd22\", \"#17becf\"\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2806907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# UTILITY FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def haversine_distance(lat1: float, lon1: float, lat2: float, lon2: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points on Earth.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lat1, lon1 : float\n",
    "        Latitude and longitude of first point in degrees\n",
    "    lat2, lon2 : float\n",
    "        Latitude and longitude of second point in degrees\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Distance in kilometers\n",
    "    \"\"\"\n",
    "    R = 6371.0  # Earth radius in km\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return R * c\n",
    "\n",
    "\n",
    "def setup_logger(verbose: bool = True):\n",
    "    \"\"\"Set up logging configuration.\"\"\"\n",
    "    import logging\n",
    "    level = logging.INFO if verbose else logging.WARNING\n",
    "    logging.basicConfig(\n",
    "        level=level,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S'\n",
    "    )\n",
    "    return logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# THERMODYNAMIC CALCULATIONS\n",
    "# ============================================================================\n",
    "\n",
    "class ThermodynamicCalculator:\n",
    "    \"\"\"Calculate thermodynamic variables for cyclone analysis.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_equivalent_potential_temperature(\n",
    "        temperature: xr.DataArray,\n",
    "        pressure: xr.DataArray,\n",
    "        specific_humidity: xr.DataArray,\n",
    "        var_names: VariableNames\n",
    "    ) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        Calculate equivalent potential temperature.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        temperature : xr.DataArray\n",
    "            Temperature in Kelvin\n",
    "        pressure : xr.DataArray\n",
    "            Pressure in Pa or hPa\n",
    "        specific_humidity : xr.DataArray\n",
    "            Specific humidity in kg/kg\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        xr.DataArray\n",
    "            Equivalent potential temperature in Kelvin\n",
    "        \"\"\"\n",
    "        # Convert to MetPy quantities\n",
    "        T = temperature.values * units.kelvin\n",
    "\n",
    "        # Handle pressure units\n",
    "        p_values = pressure.values\n",
    "        if np.nanmax(p_values) > 10000:  # Likely in Pa\n",
    "            p = p_values * units.Pa\n",
    "        else:  # Likely in hPa\n",
    "            p = p_values * units.hPa\n",
    "\n",
    "        q = specific_humidity.values * units('kg/kg')\n",
    "\n",
    "        # Calculate mixing ratio from specific humidity\n",
    "        mixing_ratio = mpcalc.mixing_ratio_from_specific_humidity(q)\n",
    "\n",
    "        # Calculate dewpoint\n",
    "        dewpoint = mpcalc.dewpoint_from_specific_humidity(p, T, q)\n",
    "\n",
    "        # Calculate equivalent potential temperature\n",
    "        theta_e = mpcalc.equivalent_potential_temperature(p, T, dewpoint)\n",
    "\n",
    "        # Create output DataArray\n",
    "        theta_e_da = xr.DataArray(\n",
    "            theta_e.magnitude,\n",
    "            coords=temperature.coords,\n",
    "            dims=temperature.dims,\n",
    "            attrs={'units': 'K', 'long_name': 'Equivalent Potential Temperature'}\n",
    "        )\n",
    "\n",
    "        return theta_e_da\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CYCLONE DETECTION AND TRACKING\n",
    "# ============================================================================\n",
    "\n",
    "class CycloneDetector:\n",
    "    \"\"\"Detect and track cyclones in gridded data.\"\"\"\n",
    "\n",
    "    def __init__(self, config: CycloneTrackingConfig, var_names: VariableNames):\n",
    "        self.config = config\n",
    "        self.var_names = var_names\n",
    "        self.logger = setup_logger()\n",
    "\n",
    "    def find_pressure_minimum(\n",
    "        self,\n",
    "        msl_pressure: xr.DataArray,\n",
    "        search_lat: Optional[Tuple[float, float]] = None,\n",
    "        search_lon: Optional[Tuple[float, float]] = None\n",
    "    ) -> Tuple[float, float, float]:\n",
    "        \"\"\"\n",
    "        Find local pressure minimum in the search domain.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        msl_pressure : xr.DataArray\n",
    "            Mean sea-level pressure field\n",
    "        search_lat : tuple, optional\n",
    "            (min_lat, max_lat) for search region\n",
    "        search_lon : tuple, optional\n",
    "            (min_lon, max_lon) for search region\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            (latitude, longitude, pressure_value) of minimum\n",
    "        \"\"\"\n",
    "        # Subset to search region if specified\n",
    "        msl = msl_pressure.copy()\n",
    "        if search_lat is not None:\n",
    "            msl = msl.sel({self.var_names.latitude: slice(*search_lat)})\n",
    "        if search_lon is not None:\n",
    "            msl = msl.sel({self.var_names.longitude: slice(*search_lon)})\n",
    "\n",
    "        # Apply local minimum filter\n",
    "        data = msl.values\n",
    "        local_min = minimum_filter(data, footprint=np.ones((\n",
    "            self.config.footprint_size, self.config.footprint_size\n",
    "        )))\n",
    "\n",
    "        # Find where data equals local minimum (local minima locations)\n",
    "        minima_mask = (data == local_min)\n",
    "\n",
    "        # Find the absolute minimum among local minima\n",
    "        if np.any(minima_mask):\n",
    "            min_indices = np.where(minima_mask & (data == np.nanmin(data[minima_mask])))\n",
    "            if len(min_indices[0]) > 0:\n",
    "                lat_idx, lon_idx = min_indices[0][0], min_indices[1][0]\n",
    "                lat = float(msl[self.var_names.latitude][lat_idx].values)\n",
    "                lon = float(msl[self.var_names.longitude][lon_idx].values)\n",
    "                pressure = float(data[lat_idx, lon_idx])\n",
    "                return lat, lon, pressure\n",
    "\n",
    "        # Fallback: return absolute minimum\n",
    "        min_idx = np.unravel_index(np.nanargmin(data), data.shape)\n",
    "        lat = float(msl[self.var_names.latitude][min_idx[0]].values)\n",
    "        lon = float(msl[self.var_names.longitude][min_idx[1]].values)\n",
    "        pressure = float(data[min_idx])\n",
    "\n",
    "        return lat, lon, pressure\n",
    "\n",
    "    def track_cyclone(\n",
    "        self,\n",
    "        dataset: xr.Dataset,\n",
    "        initial_lat: Optional[float] = None,\n",
    "        initial_lon: Optional[float] = None,\n",
    "        initial_time: Optional[str] = None\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Track cyclone through time using pressure minima.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset : xr.Dataset\n",
    "            Dataset containing msl pressure and time dimension\n",
    "        initial_lat : float, optional\n",
    "            Initial latitude for tracking\n",
    "        initial_lon : float, optional\n",
    "            Initial longitude for tracking\n",
    "        initial_time : str, optional\n",
    "            Initial time for tracking (if None, uses first time step)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            DataFrame with columns: time, lat, lon, msl_pressure, max_wind\n",
    "        \"\"\"\n",
    "        time_var = self.var_names.time\n",
    "        lat_var = self.var_names.latitude\n",
    "        lon_var = self.var_names.longitude\n",
    "\n",
    "        times = dataset[time_var].values\n",
    "        if initial_time is not None:\n",
    "            start_idx = np.where(times >= np.datetime64(initial_time))[0][0]\n",
    "        else:\n",
    "            start_idx = 0\n",
    "\n",
    "        track_data = []\n",
    "\n",
    "        # Initialize tracking\n",
    "        if initial_lat is not None and initial_lon is not None:\n",
    "            prev_lat, prev_lon = initial_lat, initial_lon\n",
    "        else:\n",
    "            # Find initial position from first time step\n",
    "            msl_first = dataset[self.var_names.msl_pressure].isel({time_var: start_idx})\n",
    "            prev_lat, prev_lon, _ = self.find_pressure_minimum(msl_first)\n",
    "\n",
    "        self.logger.info(f\"Starting cyclone tracking from ({prev_lat:.2f}, {prev_lon:.2f})\")\n",
    "\n",
    "        for t_idx in range(start_idx, len(times)):\n",
    "            time_step = times[t_idx]\n",
    "            msl_data = dataset[self.var_names.msl_pressure].isel({time_var: t_idx})\n",
    "\n",
    "            # Calculate search radius based on time step\n",
    "            if t_idx > start_idx:\n",
    "                time_diff_hours = (times[t_idx] - times[t_idx-1]) / np.timedelta64(1, 'h')\n",
    "                max_distance = (self.config.max_speed_kmh * time_diff_hours) / 111.0  # degrees\n",
    "                search_radius = max_distance + 2.0  # Add buffer\n",
    "            else:\n",
    "                search_radius = self.config.search_radius_km / 111.0\n",
    "\n",
    "            # Define search box\n",
    "            search_lat = (prev_lat - search_radius, prev_lat + search_radius)\n",
    "            search_lon = (prev_lon - search_radius, prev_lon + search_radius)\n",
    "\n",
    "            # Find pressure minimum\n",
    "            try:\n",
    "                lat, lon, pressure = self.find_pressure_minimum(\n",
    "                    msl_data, search_lat, search_lon\n",
    "                )\n",
    "\n",
    "                # Calculate maximum wind speed near cyclone center\n",
    "                max_wind = self._calculate_max_wind(dataset, t_idx, lat, lon)\n",
    "\n",
    "                track_data.append({\n",
    "                    'time': pd.Timestamp(time_step),\n",
    "                    'lat': lat,\n",
    "                    'lon': lon,\n",
    "                    'msl_pressure': pressure,\n",
    "                    'max_wind': max_wind\n",
    "                })\n",
    "\n",
    "                prev_lat, prev_lon = lat, lon\n",
    "\n",
    "            except Exception as e:\n",
    "                self.logger.warning(f\"Failed to track at time {time_step}: {e}\")\n",
    "                continue\n",
    "\n",
    "        track_df = pd.DataFrame(track_data)\n",
    "        self.logger.info(f\"Tracking complete. Found {len(track_df)} positions.\")\n",
    "\n",
    "        return track_df\n",
    "\n",
    "    def _calculate_max_wind(\n",
    "        self,\n",
    "        dataset: xr.Dataset,\n",
    "        time_idx: int,\n",
    "        center_lat: float,\n",
    "        center_lon: float,\n",
    "        radius_deg: float = 3.0\n",
    "    ) -> float:\n",
    "        \"\"\"Calculate maximum wind speed near cyclone center.\"\"\"\n",
    "        try:\n",
    "            # Get 10m wind components\n",
    "            u_var = self.var_names.u_wind_10m\n",
    "            v_var = self.var_names.v_wind_10m\n",
    "\n",
    "            if u_var not in dataset or v_var not in dataset:\n",
    "                return np.nan\n",
    "\n",
    "            u = dataset[u_var].isel({self.var_names.time: time_idx})\n",
    "            v = dataset[v_var].isel({self.var_names.time: time_idx})\n",
    "\n",
    "            # Subset around cyclone center\n",
    "            lat_slice = slice(center_lat - radius_deg, center_lat + radius_deg)\n",
    "            lon_slice = slice(center_lon - radius_deg, center_lon + radius_deg)\n",
    "\n",
    "            u_subset = u.sel({\n",
    "                self.var_names.latitude: lat_slice,\n",
    "                self.var_names.longitude: lon_slice\n",
    "            })\n",
    "            v_subset = v.sel({\n",
    "                self.var_names.latitude: lat_slice,\n",
    "                self.var_names.longitude: lon_slice\n",
    "            })\n",
    "\n",
    "            # Calculate wind speed\n",
    "            wind_speed = np.sqrt(u_subset**2 + v_subset**2)\n",
    "            max_wind = float(wind_speed.max().values)\n",
    "\n",
    "            return max_wind\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.warning(f\"Could not calculate max wind: {e}\")\n",
    "            return np.nan\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# VERTICAL STRUCTURE ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "class VerticalStructureAnalyzer:\n",
    "    \"\"\"Analyze vertical thermal structure of cyclones.\"\"\"\n",
    "\n",
    "    def __init__(self, var_names: VariableNames):\n",
    "        self.var_names = var_names\n",
    "        self.logger = setup_logger()\n",
    "        self.thermo_calc = ThermodynamicCalculator()\n",
    "\n",
    "    def extract_cross_section(\n",
    "        self,\n",
    "        dataset: xr.Dataset,\n",
    "        center_lat: float,\n",
    "        center_lon: float,\n",
    "        time_idx: int,\n",
    "        max_radius_deg: float = 10.0\n",
    "    ) -> xr.Dataset:\n",
    "        \"\"\"\n",
    "        Extract zonal cross-section through cyclone center.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset : xr.Dataset\n",
    "            3D dataset with pressure levels\n",
    "        center_lat : float\n",
    "            Cyclone center latitude\n",
    "        center_lon : float\n",
    "            Cyclone center longitude\n",
    "        time_idx : int\n",
    "            Time index\n",
    "        max_radius_deg : float\n",
    "            Maximum radius for cross-section in degrees\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        xr.Dataset\n",
    "            Cross-section with radial distance coordinate\n",
    "        \"\"\"\n",
    "        # Select time and latitude slice\n",
    "        lat_tol = 0.5  # Tolerance for latitude selection\n",
    "        ds_time = dataset.isel({self.var_names.time: time_idx})\n",
    "\n",
    "        # Select latitude closest to center\n",
    "        ds_cross = ds_time.sel({\n",
    "            self.var_names.latitude: center_lat,\n",
    "            method:'nearest'\n",
    "        })\n",
    "\n",
    "        # Select longitude range around center\n",
    "        lon_slice = slice(center_lon - max_radius_deg, center_lon + max_radius_deg)\n",
    "        ds_cross = ds_cross.sel({self.var_names.longitude: lon_slice})\n",
    "\n",
    "        # Calculate radial distance from center\n",
    "        lons = ds_cross[self.var_names.longitude].values\n",
    "        distances = []\n",
    "        for lon in lons:\n",
    "            dist = haversine_distance(center_lat, center_lon, center_lat, lon)\n",
    "            # Make western distances negative\n",
    "            if lon < center_lon:\n",
    "                dist = -dist\n",
    "            distances.append(dist)\n",
    "\n",
    "        # Add distance coordinate\n",
    "        ds_cross = ds_cross.assign_coords({'distance': (self.var_names.longitude, distances)})\n",
    "\n",
    "        return ds_cross\n",
    "\n",
    "    def compute_thermal_structure(\n",
    "        self,\n",
    "        dataset: xr.Dataset,\n",
    "        center_lat: float,\n",
    "        center_lon: float,\n",
    "        time_idx: int,\n",
    "        max_radius_deg: float = 10.0\n",
    "    ) -> Tuple[xr.DataArray, xr.DataArray]:\n",
    "        \"\"\"\n",
    "        Compute equivalent potential temperature cross-section.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            (theta_e, tangential_wind) DataArrays with distance and pressure coords\n",
    "        \"\"\"\n",
    "        # Extract cross-section\n",
    "        ds_cross = self.extract_cross_section(\n",
    "            dataset, center_lat, center_lon, time_idx, max_radius_deg\n",
    "        )\n",
    "\n",
    "        # Calculate equivalent potential temperature\n",
    "        theta_e = self.thermo_calc.calculate_equivalent_potential_temperature(\n",
    "            ds_cross[self.var_names.temperature],\n",
    "            ds_cross[self.var_names.pressure],\n",
    "            ds_cross[self.var_names.specific_humidity],\n",
    "            self.var_names\n",
    "        )\n",
    "\n",
    "        # Calculate tangential wind if available\n",
    "        try:\n",
    "            u_wind = ds_cross[self.var_names.u_wind]\n",
    "            v_wind = ds_cross[self.var_names.v_wind]\n",
    "            # Approximate tangential wind (simplified)\n",
    "            tangential_wind = np.sqrt(u_wind**2 + v_wind**2)\n",
    "        except:\n",
    "            tangential_wind = None\n",
    "\n",
    "        return theta_e, tangential_wind\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION\n",
    "# ============================================================================\n",
    "\n",
    "class CycloneVisualizer:\n",
    "    \"\"\"Create visualizations for cyclone analysis.\"\"\"\n",
    "\n",
    "    def __init__(self, plot_config: PlotConfig):\n",
    "        self.config = plot_config\n",
    "        self.logger = setup_logger()\n",
    "\n",
    "    def plot_tracks(\n",
    "        self,\n",
    "        tracks: Dict[str, pd.DataFrame],\n",
    "        reference_tracks: Optional[Dict[str, pd.DataFrame]] = None,\n",
    "        output_path: Optional[str] = None,\n",
    "        domain: Optional[Dict[str, Tuple[float, float]]] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Plot cyclone tracks for multiple experiments.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tracks : dict\n",
    "            Dictionary of {experiment_name: track_dataframe}\n",
    "        reference_tracks : dict, optional\n",
    "            Dictionary of {reference_name: track_dataframe} for ERA5/best-track\n",
    "        output_path : str, optional\n",
    "            Path to save figure\n",
    "        domain : dict, optional\n",
    "            Domain bounds {'lat': (min, max), 'lon': (min, max)}\n",
    "        \"\"\"\n",
    "        fig = plt.figure(figsize=self.config.figsize)\n",
    "        ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "        # Set domain\n",
    "        if domain:\n",
    "            ax.set_extent([\n",
    "                domain['lon'][0], domain['lon'][1],\n",
    "                domain['lat'][0], domain['lat'][1]\n",
    "            ], crs=ccrs.PlateCarree())\n",
    "\n",
    "        # Add map features\n",
    "        ax.add_feature(cfeature.COASTLINE, linewidth=0.5)\n",
    "        ax.add_feature(cfeature.BORDERS, linewidth=0.3, linestyle=':')\n",
    "        ax.add_feature(cfeature.LAND, facecolor='lightgray', alpha=0.3)\n",
    "        ax.add_feature(cfeature.OCEAN, facecolor='lightblue', alpha=0.3)\n",
    "\n",
    "        # Plot reference tracks first (dashed lines)\n",
    "        if reference_tracks:\n",
    "            for idx, (name, track) in enumerate(reference_tracks.items()):\n",
    "                ax.plot(\n",
    "                    track['lon'], track['lat'],\n",
    "                    linestyle='--', linewidth=2.5, alpha=0.8,\n",
    "                    color='black', label=name, transform=ccrs.PlateCarree()\n",
    "                )\n",
    "                # Mark start and end\n",
    "                ax.scatter(track['lon'].iloc[0], track['lat'].iloc[0],\n",
    "                          marker='o', s=100, color='green', edgecolors='black',\n",
    "                          transform=ccrs.PlateCarree(), zorder=5)\n",
    "                ax.scatter(track['lon'].iloc[-1], track['lat'].iloc[-1],\n",
    "                          marker='s', s=100, color='red', edgecolors='black',\n",
    "                          transform=ccrs.PlateCarree(), zorder=5)\n",
    "\n",
    "        # Plot experiment tracks\n",
    "        for idx, (name, track) in enumerate(tracks.items()):\n",
    "            color = self.config.colors[idx % len(self.config.colors)]\n",
    "            ax.plot(\n",
    "                track['lon'], track['lat'],\n",
    "                linestyle='-', linewidth=2, alpha=0.7,\n",
    "                color=color, label=name, transform=ccrs.PlateCarree()\n",
    "            )\n",
    "            # Mark start\n",
    "            ax.scatter(track['lon'].iloc[0], track['lat'].iloc[0],\n",
    "                      marker='o', s=80, color=color, edgecolors='black',\n",
    "                      alpha=0.7, transform=ccrs.PlateCarree(), zorder=4)\n",
    "\n",
    "        # Add gridlines\n",
    "        gl = ax.gridlines(draw_labels=True, linestyle='--', alpha=0.5)\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "\n",
    "        # Add legend\n",
    "        ax.legend(loc='upper left', fontsize=10, framealpha=0.9)\n",
    "\n",
    "        plt.title('Cyclone Tracks Comparison', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if output_path:\n",
    "            plt.savefig(output_path, dpi=self.config.dpi, bbox_inches='tight')\n",
    "            self.logger.info(f\"Track plot saved to {output_path}\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def plot_pressure_evolution(\n",
    "        self,\n",
    "        tracks: Dict[str, pd.DataFrame],\n",
    "        reference_tracks: Optional[Dict[str, pd.DataFrame]] = None,\n",
    "        output_path: Optional[str] = None\n",
    "    ):\n",
    "        \"\"\"Plot minimum pressure evolution over time.\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=self.config.figsize)\n",
    "\n",
    "        # Plot reference tracks\n",
    "        if reference_tracks:\n",
    "            for name, track in reference_tracks.items():\n",
    "                ax.plot(track['time'], track['msl_pressure'],\n",
    "                       linestyle='--', linewidth=2.5, color='black',\n",
    "                       alpha=0.8, label=name)\n",
    "\n",
    "        # Plot experiment tracks\n",
    "        for idx, (name, track) in enumerate(tracks.items()):\n",
    "            color = self.config.colors[idx % len(self.config.colors)]\n",
    "            ax.plot(track['time'], track['msl_pressure'],\n",
    "                   linestyle='-', linewidth=2, color=color,\n",
    "                   alpha=0.7, label=name, marker='o', markersize=4)\n",
    "\n",
    "        ax.set_xlabel('Time', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel('Mean Sea-Level Pressure (hPa)', fontsize=12, fontweight='bold')\n",
    "        ax.set_title('Cyclone Minimum Pressure Evolution', fontsize=14, fontweight='bold')\n",
    "        ax.legend(fontsize=10, framealpha=0.9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # Invert y-axis (lower pressure at top)\n",
    "        ax.invert_yaxis()\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if output_path:\n",
    "            plt.savefig(output_path, dpi=self.config.dpi, bbox_inches='tight')\n",
    "            self.logger.info(f\"Pressure evolution plot saved to {output_path}\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def plot_wind_evolution(\n",
    "        self,\n",
    "        tracks: Dict[str, pd.DataFrame],\n",
    "        reference_tracks: Optional[Dict[str, pd.DataFrame]] = None,\n",
    "        output_path: Optional[str] = None\n",
    "    ):\n",
    "        \"\"\"Plot maximum wind speed evolution over time.\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=self.config.figsize)\n",
    "\n",
    "        # Plot reference tracks\n",
    "        if reference_tracks:\n",
    "            for name, track in reference_tracks.items():\n",
    "                if 'max_wind' in track.columns:\n",
    "                    ax.plot(track['time'], track['max_wind'],\n",
    "                           linestyle='--', linewidth=2.5, color='black',\n",
    "                           alpha=0.8, label=name)\n",
    "\n",
    "        # Plot experiment tracks\n",
    "        for idx, (name, track) in enumerate(tracks.items()):\n",
    "            if 'max_wind' in track.columns:\n",
    "                color = self.config.colors[idx % len(self.config.colors)]\n",
    "                ax.plot(track['time'], track['max_wind'],\n",
    "                       linestyle='-', linewidth=2, color=color,\n",
    "                       alpha=0.7, label=name, marker='o', markersize=4)\n",
    "\n",
    "        ax.set_xlabel('Time', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel('Maximum Wind Speed (m/s)', fontsize=12, fontweight='bold')\n",
    "        ax.set_title('Cyclone Maximum Wind Speed Evolution', fontsize=14, fontweight='bold')\n",
    "        ax.legend(fontsize=10, framealpha=0.9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if output_path:\n",
    "            plt.savefig(output_path, dpi=self.config.dpi, bbox_inches='tight')\n",
    "            self.logger.info(f\"Wind evolution plot saved to {output_path}\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def plot_vertical_structure(\n",
    "        self,\n",
    "        theta_e: xr.DataArray,\n",
    "        distance_coord: str = 'distance',\n",
    "        pressure_coord: str = 'plev',\n",
    "        tangential_wind: Optional[xr.DataArray] = None,\n",
    "        output_path: Optional[str] = None,\n",
    "        title: str = 'Vertical Thermal Structure'\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Plot vertical cross-section of equivalent potential temperature.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        theta_e : xr.DataArray\n",
    "            Equivalent potential temperature with distance and pressure dimensions\n",
    "        distance_coord : str\n",
    "            Name of distance coordinate\n",
    "        pressure_coord : str\n",
    "            Name of pressure coordinate\n",
    "        tangential_wind : xr.DataArray, optional\n",
    "            Tangential wind component for contouring\n",
    "        output_path : str, optional\n",
    "            Path to save figure\n",
    "        title : str\n",
    "            Plot title\n",
    "        \"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "        # Prepare data\n",
    "        distance = theta_e[distance_coord].values\n",
    "        pressure = theta_e[pressure_coord].values\n",
    "\n",
    "        # Convert pressure to hPa if needed\n",
    "        if np.max(pressure) > 10000:\n",
    "            pressure = pressure / 100.0\n",
    "\n",
    "        # Create meshgrid\n",
    "        X, Y = np.meshgrid(distance, pressure)\n",
    "\n",
    "        # Plot theta_e as filled contours\n",
    "        levels_theta = np.arange(300, 380, 2)\n",
    "        cf = ax.contourf(X, Y, theta_e.T, levels=levels_theta,\n",
    "                        cmap='RdYlBu_r', extend='both')\n",
    "\n",
    "        # Add colorbar\n",
    "        cbar = plt.colorbar(cf, ax=ax, orientation='vertical', pad=0.02)\n",
    "        cbar.set_label('Equivalent Potential Temperature (K)',\n",
    "                      fontsize=12, fontweight='bold')\n",
    "\n",
    "        # Overlay tangential wind as contours if available\n",
    "        if tangential_wind is not None:\n",
    "            levels_wind = np.arange(10, 50, 5)\n",
    "            cs = ax.contour(X, Y, tangential_wind.T, levels=levels_wind,\n",
    "                          colors='black', linewidths=1.5, alpha=0.6)\n",
    "            ax.clabel(cs, inline=True, fontsize=9, fmt='%d m/s')\n",
    "\n",
    "        # Format axes\n",
    "        ax.set_xlabel('Distance from Center (km)', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel('Pressure (hPa)', fontsize=12, fontweight='bold')\n",
    "        ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "\n",
    "        # Invert y-axis (pressure increases downward)\n",
    "        ax.invert_yaxis()\n",
    "\n",
    "        # Set y-axis to show common pressure levels\n",
    "        ax.set_yticks([1000, 925, 850, 700, 500, 400, 300, 250, 200])\n",
    "\n",
    "        # Add vertical line at center\n",
    "        ax.axvline(x=0, color='black', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if output_path:\n",
    "            plt.savefig(output_path, dpi=self.config.dpi, bbox_inches='tight')\n",
    "            self.logger.info(f\"Vertical structure plot saved to {output_path}\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# DATA LOADING AND MANAGEMENT\n",
    "# ============================================================================\n",
    "\n",
    "class DataManager:\n",
    "    \"\"\"Manage loading and preprocessing of model and reference data.\"\"\"\n",
    "\n",
    "    def __init__(self, var_names: VariableNames):\n",
    "        self.var_names = var_names\n",
    "        self.logger = setup_logger()\n",
    "\n",
    "    def load_model_output(\n",
    "        self,\n",
    "        file_paths: Union[str, List[str]],\n",
    "        chunks: Optional[Dict] = None\n",
    "    ) -> xr.Dataset:\n",
    "        \"\"\"\n",
    "        Load model output files.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        file_paths : str or list\n",
    "            Path(s) to model output NetCDF files\n",
    "        chunks : dict, optional\n",
    "            Chunking specification for dask\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        xr.Dataset\n",
    "            Loaded dataset\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if isinstance(file_paths, str):\n",
    "                ds = xr.open_dataset(file_paths, chunks=chunks)\n",
    "            else:\n",
    "                ds = xr.open_mfdataset(file_paths, combine='by_coords', chunks=chunks)\n",
    "\n",
    "            self.logger.info(f\"Loaded dataset with dimensions: {dict(ds.dims)}\")\n",
    "            return ds\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to load data: {e}\")\n",
    "            raise\n",
    "\n",
    "    def load_era5_data(\n",
    "        self,\n",
    "        file_paths: Union[str, List[str]],\n",
    "        var_mapping: Optional[Dict[str, str]] = None\n",
    "    ) -> xr.Dataset:\n",
    "        \"\"\"\n",
    "        Load ERA5 reanalysis data and standardize variable names.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        file_paths : str or list\n",
    "            Path(s) to ERA5 NetCDF files\n",
    "        var_mapping : dict, optional\n",
    "            Mapping from ERA5 variable names to standard names\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        xr.Dataset\n",
    "            Loaded and standardized dataset\n",
    "        \"\"\"\n",
    "        ds = self.load_model_output(file_paths)\n",
    "\n",
    "        # Default ERA5 variable mapping\n",
    "        if var_mapping is None:\n",
    "            var_mapping = {\n",
    "                'msl': self.var_names.msl_pressure,\n",
    "                't': self.var_names.temperature,\n",
    "                'q': self.var_names.specific_humidity,\n",
    "                'u': self.var_names.u_wind,\n",
    "                'v': self.var_names.v_wind,\n",
    "                'u10': self.var_names.u_wind_10m,\n",
    "                'v10': self.var_names.v_wind_10m,\n",
    "            }\n",
    "\n",
    "        # Rename variables\n",
    "        rename_dict = {k: v for k, v in var_mapping.items() if k in ds}\n",
    "        if rename_dict:\n",
    "            ds = ds.rename(rename_dict)\n",
    "            self.logger.info(f\"Renamed ERA5 variables: {rename_dict}\")\n",
    "\n",
    "        return ds\n",
    "\n",
    "    def load_best_track(\n",
    "        self,\n",
    "        file_path: str,\n",
    "        format: str = 'csv'\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Load NOAA best-track data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        file_path : str\n",
    "            Path to best-track file\n",
    "        format : str\n",
    "            File format ('csv', 'txt', 'hurdat2')\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            Best-track data with columns: time, lat, lon, msl_pressure, max_wind\n",
    "        \"\"\"\n",
    "        if format == 'csv':\n",
    "            df = pd.read_csv(file_path, parse_dates=['time'])\n",
    "        elif format == 'hurdat2':\n",
    "            df = self._parse_hurdat2(file_path)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported format: {format}\")\n",
    "\n",
    "        self.logger.info(f\"Loaded best-track data with {len(df)} records\")\n",
    "        return df\n",
    "\n",
    "    def _parse_hurdat2(self, file_path: str) -> pd.DataFrame:\n",
    "        \"\"\"Parse HURDAT2 format best-track file.\"\"\"\n",
    "        # Implementation for HURDAT2 format\n",
    "        # This is a placeholder - actual implementation depends on file structure\n",
    "        raise NotImplementedError(\"HURDAT2 parsing not yet implemented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b20078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_regcm5_multi_file(data_dir, verbose=False):\n",
    "    \"\"\"\n",
    "    Load RegCM5 data from separate variable files and merge into single dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_dir : str\n",
    "        Directory containing separate NetCDF files for each variable\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    xr.Dataset\n",
    "        Merged dataset with all variables\n",
    "    \"\"\"\n",
    "    nc_files = sorted(glob.glob(os.path.join(data_dir, '*.nc')))\n",
    "    datasets = []\n",
    "\n",
    "    for file in nc_files:\n",
    "        ds_temp = xr.open_dataset(file)\n",
    "        datasets.append(ds_temp)\n",
    "        \n",
    "    ds_merged = xr.merge(datasets, compat='override')\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nMerged dataset:\")\n",
    "        print(f\"  Variables: {list(ds_merged.data_vars)}\")\n",
    "        print(f\"  Dimensions: {dict(ds_merged.dims)}\")\n",
    "        print(f\"  Coordinates: {list(ds_merged.coords)}\")\n",
    "    \n",
    "    return ds_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00dfc05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged dataset:\n",
      "  Variables: ['hus', 'time_bnds', 'pr', 'psl', 'ta', 'ua', 'va', 'wa']\n",
      "  Dimensions: {'time': 193, 'lon': 417, 'lat': 417, 'plev': 21, 'bnds': 2}\n",
      "  Coordinates: ['time', 'lon', 'lat', 'plev']\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'data/domain_small_regridded/ctrl'\n",
    "ds = load_regcm5_multi_file(data_dir, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8f27756",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycloneAnalysis:\n",
    "    \"\"\"Main pipeline for cyclone tracking and analysis.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        var_names: Optional[VariableNames] = None,\n",
    "        tracking_config: Optional[CycloneTrackingConfig] = None,\n",
    "        plot_config: Optional[PlotConfig] = None\n",
    "    ):\n",
    "        self.var_names = var_names or VariableNames()\n",
    "        self.tracking_config = tracking_config or CycloneTrackingConfig()\n",
    "        self.plot_config = plot_config or PlotConfig()\n",
    "\n",
    "        self.detector = CycloneDetector(self.tracking_config, self.var_names)\n",
    "        self.vertical_analyzer = VerticalStructureAnalyzer(self.var_names)\n",
    "        self.visualizer = CycloneVisualizer(self.plot_config)\n",
    "        self.data_manager = DataManager(self.var_names)\n",
    "        self.logger = setup_logger()\n",
    "\n",
    "    def analyze_experiment(\n",
    "        self,\n",
    "        ds: xr.Dataset,\n",
    "        experiment_name: str,\n",
    "        initial_position: Optional[Tuple[float, float]] = None,\n",
    "        initial_time: Optional[str] = None\n",
    "    ) -> Tuple[pd.DataFrame, xr.Dataset]:\n",
    "        \"\"\"\n",
    "        Analyze a single experiment.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_path : str or list\n",
    "            Path(s) to model output files\n",
    "        experiment_name : str\n",
    "            Name of experiment\n",
    "        initial_position : tuple, optional\n",
    "            (lat, lon) initial position\n",
    "        initial_time : str, optional\n",
    "            Initial time for tracking\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            (track_dataframe, dataset)\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"Analyzing experiment: {experiment_name}\")\n",
    "\n",
    "        # Load data\n",
    "        #ds = self.data_manager.load_model_output(data_path)\n",
    "\n",
    "        # Track cyclone\n",
    "        initial_lat = initial_position[0] if initial_position else None\n",
    "        initial_lon = initial_position[1] if initial_position else None\n",
    "\n",
    "        track = self.detector.track_cyclone(\n",
    "            ds, initial_lat, initial_lon, initial_time\n",
    "        )\n",
    "\n",
    "        return track, ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "502962fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "otis = CycloneAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa064ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-21 12:02:35 - INFO - Analyzing experiment: ctrl\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All-NaN slice encountered",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m data_path = \u001b[33m\"\u001b[39m\u001b[33mdata/domain_small\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43motis\u001b[49m\u001b[43m.\u001b[49m\u001b[43manalyze_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mctrl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 55\u001b[39m, in \u001b[36mCycloneAnalysis.analyze_experiment\u001b[39m\u001b[34m(self, ds, experiment_name, initial_position, initial_time)\u001b[39m\n\u001b[32m     52\u001b[39m initial_lat = initial_position[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m initial_position \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     53\u001b[39m initial_lon = initial_position[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m initial_position \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m track = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdetector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrack_cyclone\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_lat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_lon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_time\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m track, ds\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 218\u001b[39m, in \u001b[36mCycloneDetector.track_cyclone\u001b[39m\u001b[34m(self, dataset, initial_lat, initial_lon, initial_time)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    216\u001b[39m     \u001b[38;5;66;03m# Find initial position from first time step\u001b[39;00m\n\u001b[32m    217\u001b[39m     msl_first = dataset[\u001b[38;5;28mself\u001b[39m.var_names.msl_pressure].isel({time_var: start_idx})\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     prev_lat, prev_lon, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfind_pressure_minimum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsl_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[38;5;28mself\u001b[39m.logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStarting cyclone tracking from (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprev_lat\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprev_lon\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_idx, \u001b[38;5;28mlen\u001b[39m(times)):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 167\u001b[39m, in \u001b[36mCycloneDetector.find_pressure_minimum\u001b[39m\u001b[34m(self, msl_pressure, search_lat, search_lon)\u001b[39m\n\u001b[32m    164\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m lat, lon, pressure\n\u001b[32m    166\u001b[39m \u001b[38;5;66;03m# Fallback: return absolute minimum\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m min_idx = np.unravel_index(\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnanargmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m, data.shape)\n\u001b[32m    168\u001b[39m lat = \u001b[38;5;28mfloat\u001b[39m(msl[\u001b[38;5;28mself\u001b[39m.var_names.latitude][min_idx[\u001b[32m0\u001b[39m]].values)\n\u001b[32m    169\u001b[39m lon = \u001b[38;5;28mfloat\u001b[39m(msl[\u001b[38;5;28mself\u001b[39m.var_names.longitude][min_idx[\u001b[32m1\u001b[39m]].values)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/geostat/lib/python3.11/site-packages/numpy/lib/nanfunctions.py:552\u001b[39m, in \u001b[36mnanargmin\u001b[39m\u001b[34m(a, axis, out, keepdims)\u001b[39m\n\u001b[32m    550\u001b[39m     mask = np.all(mask, axis=axis)\n\u001b[32m    551\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m np.any(mask):\n\u001b[32m--> \u001b[39m\u001b[32m552\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAll-NaN slice encountered\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    553\u001b[39m res = np.argmin(a, axis=axis, out=out, keepdims=keepdims)\n\u001b[32m    554\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[31mValueError\u001b[39m: All-NaN slice encountered"
     ]
    }
   ],
   "source": [
    "data_path = \"data/domain_small\"\n",
    "otis.analyze_experiment(ds=ds, experiment_name=\"ctrl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ee86f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pressure_minimum(\n",
    "        msl_pressure: xr.DataArray,\n",
    "        search_lat: Optional[Tuple[float, float]] = None,\n",
    "        search_lon: Optional[Tuple[float, float]] = None\n",
    "    ) -> Tuple[float, float, float]:\n",
    "        \"\"\"\n",
    "        Find local pressure minimum in the search domain.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        msl_pressure : xr.DataArray\n",
    "            Mean sea-level pressure field\n",
    "        search_lat : tuple, optional\n",
    "            (min_lat, max_lat) for search region\n",
    "        search_lon : tuple, optional\n",
    "            (min_lon, max_lon) for search region\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            (latitude, longitude, pressure_value) of minimum\n",
    "        \"\"\"\n",
    "        # Subset to search region if specified\n",
    "        msl = msl_pressure.copy()\n",
    "        if search_lat is not None:\n",
    "            msl = msl.sel({self.var_names.latitude: slice(*search_lat)})\n",
    "        if search_lon is not None:\n",
    "            msl = msl.sel({self.var_names.longitude: slice(*search_lon)})\n",
    "\n",
    "        # Apply local minimum filter\n",
    "        data = msl.values\n",
    "        local_min = minimum_filter(data, footprint=np.ones((\n",
    "            self.config.footprint_size, self.config.footprint_size\n",
    "        )))\n",
    "\n",
    "        # Find where data equals local minimum (local minima locations)\n",
    "        minima_mask = (data == local_min)\n",
    "\n",
    "        # Find the absolute minimum among local minima\n",
    "        if np.any(minima_mask):\n",
    "            min_indices = np.where(minima_mask & (data == np.nanmin(data[minima_mask])))\n",
    "            if len(min_indices[0]) > 0:\n",
    "                lat_idx, lon_idx = min_indices[0][0], min_indices[1][0]\n",
    "                lat = float(msl[self.var_names.latitude][lat_idx].values)\n",
    "                lon = float(msl[self.var_names.longitude][lon_idx].values)\n",
    "                pressure = float(data[lat_idx, lon_idx])\n",
    "                return lat, lon, pressure\n",
    "\n",
    "        # Fallback: return absolute minimum\n",
    "        try:\n",
    "            min_idx = np.unravel_index(np.nanargmin(data), data.shape)\n",
    "            lat = float(msl[self.var_names.latitude][min_idx[0]].values)\n",
    "            lon = float(msl[self.var_names.longitude][min_idx[1]].values)\n",
    "            pressure = float(data[min_idx])\n",
    "\n",
    "            return lat, lon, pressure\n",
    "        except:\n",
    "            return np.nan, np.nan, np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968f798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_pressure_minimum(ds.psl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
